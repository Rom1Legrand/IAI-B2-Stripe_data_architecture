# Stripe Project - OLTP, OLAP, and NoSQL Architecture

---

## ğŸ“š Table of Contents
- [ğŸ¯ Context and Goals](#-context-and-goals)
- [ğŸ› ï¸ Overall Architecture](#ï¸-overall-architecture)
- [ğŸ’¾ Databases and Technologies](#-databases-and-technologies)
- [ğŸ”„ Data Pipeline and Flow](#-data-pipeline-and-flow)
- [â˜ï¸ Cloud Infrastructure and Monitoring](#ï¸-cloud-infrastructure-and-monitoring)
- [ğŸ”’ Security and Compliance](#-security-and-compliance)
- [ğŸ“ Notes and Next Steps](#-notes-and-next-steps)
- [ğŸ“‚ Annexes](#-annexes)

---

## ğŸ¯ Context and Goals
Stripe processes millions of transactions daily, requiring a scalable infrastructure to handle:
- **OLTP (Online Transaction Processing):** Efficient real-time transaction processing.
- **OLAP (Online Analytical Processing):** Complex data analysis and reporting.
- **NoSQL:** Management of semi-structured and unstructured data for use cases like fraud detection and customer personalization.

This project aims to design an integrated and scalable architecture to address these needs using **PostgreSQL**, **Snowflake**, and **MongoDB** on **AWS**.

---

## ğŸ› ï¸ Overall Architecture
The architecture revolves around three key components:
1. **OLTP:** PostgreSQL (or NeonDB for a managed cloud solution).
2. **OLAP:** Snowflake for advanced analytics.
3. **NoSQL:** MongoDB for semi-structured data (ML features, error logs, etc.).

### ğŸŒŸ Architecture Diagram
*[View Architecture Diagram (PDF)](STRIPE_ARCHITECTURE.pdf)*

---

## ğŸ’¾ Databases and Technologies

### 1. **OLTP - PostgreSQL**
- **Purpose:** Real-time transaction management.
- **Structure:** Relational database with normalized tables (e.g., Transaction, Customer, Merchant).
- **Deployment Options:**
  - Local: Using Docker for development.
  - Cloud: Using NeonDB for a managed database.

### 2. **OLAP - Snowflake**
- **Purpose:** Historical data analysis and reporting.
- **Structure:** Star schema (fact and dimension tables).
- **Use Cases:**
  - Fact tables for transactions.
  - Dimension tables: customer, product, location, etc.

### 3. **NoSQL - MongoDB**
- **Purpose:** Storage for unstructured data.
- **Primary Collections:**
  - Transactions
  - Error logs
  - ML features for training

---

## ğŸ”„ Data Pipeline and Flow

### **Ingestion**
- **Kafka:** Real-time event ingestion.
- **Debezium:** Change Data Capture (CDC) for syncing PostgreSQL with Snowflake and MongoDB.
- **S3:** Intermediate storage for raw data.

### **ETL Transformation**
- **Spark:** Cleaning, enrichment, and aggregation of data.
- **Airbyte:** Synchronizing data with Snowflake and MongoDB.

### **Analytics and Reporting**
- Processed data is stored in Snowflake and visualized using BI tools like Tableau or Power BI.

### **Machine Learning**
- **MLflow:** Training and tracking ML models for:
  - Fraud detection.
  - Customer personalization.
- **ML Pipeline:** Models are deployed to production and monitored with Evidently.AI.

---

## â˜ï¸ Cloud Infrastructure and Monitoring

### **AWS Cloud**
- **S3:** Backup of raw data and ML models.
- **CloudWatch:** Performance monitoring.

### **Model Monitoring**
- **Airflow:** Workflow orchestration and alerts.
- **Evidently.AI:** Monitoring model drift in production.

---

## ğŸ”’ Security and Compliance

### **Access Control**
- **IAM roles** for AWS resources.
- **Role-Based Access Control (RBAC)** for PostgreSQL, Snowflake, and MongoDB.
- **SSO** authentication.

### **Encryption**
- **In-transit:** TLS.
- **At-rest:** AES-256 encryption.

### **Compliance**
- User action logging.
- Automatic backups and Point-In-Time Recovery (PITR).

---

## ğŸ“ Notes and Next Steps

### **Data Replication**
- Set up automatic replication in MongoDB and Snowflake.
  
### **ML Pipeline Improvement**
- Test additional models for fraud detection.

### **Production Migration**
- Migrate local PostgreSQL to NeonDB for scalability.

  ---

## ğŸ“‚ Annexes

- Diagrams (achitecture, OLTP, OLAP, NoSQL)
- Notebook: Database creation and query examples.
- Technical documentation
